{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import transformations as TR\n",
    "import utils as UT\n",
    "import json\n",
    "import train_model as TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 14:21:51,971] [INFO] [utils]: Logger set up: ./logs.log\n"
     ]
    }
   ],
   "source": [
    "UT.setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"config\": \"./config.yaml\",\n",
    "    \"override\": json.dumps({\n",
    "        \"mlflow.mlflow_experiment_name\": \"n_clusters_investigation\",\n",
    "        \"model.kmeans.params.model_params.n_clusters\": 2\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 00:30:12,902] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 00:30:12,914] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 00:30:13,114] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n",
      "2025/01/02 00:30:13 INFO mlflow.tracking.fluent: Experiment with name 'n_clusters_investigation' does not exist. Creating a new experiment.\n",
      "[2025-01-02 00:30:13,135] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 00:30:13,135] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 00:30:13,266] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 00:30:13,266] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 00:30:13,568] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 00:30:13,568] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 00:30:13,866] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 2}\n",
      "[2025-01-02 00:30:14,348] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 00:30:14,701] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 00:30:14,718] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 00:30:14,718] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 00:30:14,732] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 00:30:18,936] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 00:30:18,936] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 01:15:16,912] [INFO] [evaluation]: Silhouette Score: 0.257\n",
      "[2025-01-02 01:15:16,912] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 01:15:16,912] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 3386381.894\n",
      "[2025-01-02 01:15:16,912] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.25664677212100584), 'inertia': 3386381.893954085}\n",
      "[2025-01-02 01:15:16,912] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 01:15:16,926] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 01:15:16,926] [INFO] [train_model]: log params: {'n_clusters': 2, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 01:15:16,926] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 01:15:17,128] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 01:15:17,128] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 01:15:17,309] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 01:15:17,309] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 01:15:17,309] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 01:15:17,448] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 01:15:17,449] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 01:15:17,709] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 01:15:17,726] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 01:15:17,976] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 3}\n",
      "[2025-01-02 01:15:18,311] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 01:15:18,556] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 01:15:18,559] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 01:15:18,572] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 01:15:18,575] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 01:15:21,492] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 01:15:21,492] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 02:00:16,691] [INFO] [evaluation]: Silhouette Score: 0.276\n",
      "[2025-01-02 02:00:16,693] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 02:00:16,694] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2731229.427\n",
      "[2025-01-02 02:00:16,694] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.2763466800819722), 'inertia': 2731229.4265126092}\n",
      "[2025-01-02 02:00:16,695] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 02:00:16,700] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 02:00:16,704] [INFO] [train_model]: log params: {'n_clusters': 3, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 02:00:16,712] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 02:00:16,916] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 02:00:16,917] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 02:00:17,096] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 02:00:17,100] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 02:00:17,101] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 02:00:17,232] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 02:00:17,233] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 02:00:17,508] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 02:00:17,508] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 02:00:17,772] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 4}\n",
      "[2025-01-02 02:00:18,315] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 02:00:18,549] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 02:00:18,558] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 02:00:18,564] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 02:00:18,568] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 02:00:21,562] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 02:00:21,563] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 02:44:55,904] [INFO] [evaluation]: Silhouette Score: 0.260\n",
      "[2025-01-02 02:44:55,920] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 02:44:55,920] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2520259.924\n",
      "[2025-01-02 02:44:55,921] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.26006017786899005), 'inertia': 2520259.9236601223}\n",
      "[2025-01-02 02:44:55,922] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 02:44:55,926] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 02:44:55,929] [INFO] [train_model]: log params: {'n_clusters': 4, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 02:44:55,937] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 02:44:56,129] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 02:44:56,131] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 02:44:56,304] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n",
      "[2025-01-02 02:44:56,304] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 02:44:56,304] [INFO] [transformations]: Standard scaling pipeline built successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 02:44:56,443] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 02:44:56,444] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 02:44:56,705] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 02:44:56,705] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 02:44:56,981] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 5}\n",
      "[2025-01-02 02:44:57,405] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 02:44:57,655] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 02:44:57,664] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 02:44:57,670] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 02:44:57,674] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 02:45:00,649] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 02:45:00,650] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 03:29:21,643] [INFO] [evaluation]: Silhouette Score: 0.184\n",
      "[2025-01-02 03:29:21,643] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 03:29:21,643] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2168251.348\n",
      "[2025-01-02 03:29:21,643] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.18433768932848285), 'inertia': 2168251.34765663}\n",
      "[2025-01-02 03:29:21,643] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 03:29:21,659] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 03:29:21,659] [INFO] [train_model]: log params: {'n_clusters': 5, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 03:29:21,659] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 03:29:21,862] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 03:29:21,862] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 03:29:22,049] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 03:29:22,049] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 03:29:22,049] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 03:29:22,174] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 03:29:22,174] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 03:29:22,456] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 03:29:22,456] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 03:29:22,721] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 6}\n",
      "[2025-01-02 03:29:23,206] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 03:29:23,425] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 03:29:23,440] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 03:29:23,440] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 03:29:23,456] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 03:29:26,408] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 03:29:26,408] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 04:14:08,730] [INFO] [evaluation]: Silhouette Score: 0.184\n",
      "[2025-01-02 04:14:08,731] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 04:14:08,732] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2253367.059\n",
      "[2025-01-02 04:14:08,734] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.18391696641130154), 'inertia': 2253367.0588187906}\n",
      "[2025-01-02 04:14:08,734] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 04:14:08,739] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 04:14:08,742] [INFO] [train_model]: log params: {'n_clusters': 6, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 04:14:08,750] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 04:14:08,940] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 04:14:08,941] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 04:14:09,137] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 04:14:09,143] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 04:14:09,143] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 04:14:09,279] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 04:14:09,280] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 04:14:09,547] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 04:14:09,551] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 04:14:09,826] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 7}\n",
      "[2025-01-02 04:14:10,482] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 04:14:10,709] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 04:14:10,711] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 04:14:10,721] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 04:14:10,727] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 04:14:13,753] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 04:14:13,754] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 04:58:10,240] [INFO] [evaluation]: Silhouette Score: 0.211\n",
      "[2025-01-02 04:58:10,241] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 04:58:10,242] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 1860495.404\n",
      "[2025-01-02 04:58:10,242] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.21138744276514818), 'inertia': 1860495.4039449957}\n",
      "[2025-01-02 04:58:10,243] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 04:58:10,247] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 04:58:10,250] [INFO] [train_model]: log params: {'n_clusters': 7, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 04:58:10,258] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 04:58:10,345] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 04:58:10,346] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 04:58:10,522] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n",
      "[2025-01-02 04:58:10,526] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 04:58:10,527] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 04:58:10,659] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 04:58:10,659] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 04:58:10,929] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 04:58:10,930] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 04:58:11,201] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 8}\n",
      "[2025-01-02 04:58:11,758] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 04:58:12,022] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 04:58:12,038] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 04:58:12,050] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 04:58:12,063] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 04:58:15,184] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 04:58:15,184] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 05:43:01,893] [INFO] [evaluation]: Silhouette Score: 0.195\n",
      "[2025-01-02 05:43:01,894] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 05:43:01,895] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 1736646.435\n",
      "[2025-01-02 05:43:01,896] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.19544172712263433), 'inertia': 1736646.434945915}\n",
      "[2025-01-02 05:43:01,896] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 05:43:01,900] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 05:43:01,903] [INFO] [train_model]: log params: {'n_clusters': 8, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 05:43:01,911] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 05:43:01,992] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 05:43:01,993] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 05:43:02,168] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 05:43:02,172] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 05:43:02,172] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 05:43:02,301] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 05:43:02,302] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 05:43:02,572] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 05:43:02,573] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 05:43:02,839] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 9}\n",
      "[2025-01-02 05:43:03,395] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 05:43:03,627] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 05:43:03,636] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 05:43:03,641] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 05:43:03,646] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 05:43:06,722] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 05:43:06,723] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 06:27:52,782] [INFO] [evaluation]: Silhouette Score: 0.204\n",
      "[2025-01-02 06:27:52,783] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 06:27:52,784] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 1628546.615\n",
      "[2025-01-02 06:27:52,785] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.20420919000164117), 'inertia': 1628546.6151427494}\n",
      "[2025-01-02 06:27:52,785] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 06:27:52,789] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 06:27:52,792] [INFO] [train_model]: log params: {'n_clusters': 9, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 06:27:52,800] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 06:27:52,882] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 06:27:52,883] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 06:27:53,045] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n",
      "[2025-01-02 06:27:53,049] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 06:27:53,050] [INFO] [transformations]: Standard scaling pipeline built successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 06:27:53,179] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 06:27:53,180] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 06:27:53,476] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 06:27:53,477] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 06:27:53,742] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 10}\n",
      "[2025-01-02 06:27:54,533] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 06:27:54,762] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 06:27:54,771] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 06:27:54,777] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 06:27:54,780] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 06:27:57,774] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 06:27:57,774] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 07:12:44,559] [INFO] [evaluation]: Silhouette Score: 0.200\n",
      "[2025-01-02 07:12:44,560] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 07:12:44,561] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 1579397.714\n",
      "[2025-01-02 07:12:44,562] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.1998325056340932), 'inertia': 1579397.7143130484}\n",
      "[2025-01-02 07:12:44,562] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 07:12:44,566] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 07:12:44,569] [INFO] [train_model]: log params: {'n_clusters': 10, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 07:12:44,577] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "cluster_range = range(2, 11)\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    print(f\"Running pipeline with n_clusters={n_clusters}\")\n",
    "    \n",
    "    args_dict[\"override\"] = json.dumps({\n",
    "        \"mlflow.mlflow_experiment_name\": \"n_clusters_investigation\",\n",
    "        \"model.kmeans.params.model_params.n_clusters\": n_clusters\n",
    "    })\n",
    "    \n",
    "    TM.run_training_pipeline(args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 14:22:00,806] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 14:22:00,806] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 14:22:01,001] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/02 14:22:01 INFO mlflow.tracking.fluent: Experiment with name 'two_clusterings' does not exist. Creating a new experiment.\n",
      "[2025-01-02 14:22:01,022] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 14:22:01,022] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 14:22:01,152] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 14:22:01,152] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 14:22:01,440] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 14:22:01,440] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 14:22:01,719] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 3}\n",
      "[2025-01-02 14:22:02,219] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 14:22:02,553] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 14:22:02,569] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 14:22:02,585] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 14:22:02,588] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 14:22:06,600] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 14:22:06,601] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 15:07:17,642] [INFO] [evaluation]: Silhouette Score: 0.276\n",
      "[2025-01-02 15:07:17,644] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 15:07:17,645] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2731229.427\n",
      "[2025-01-02 15:07:17,646] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.2763466800819722), 'inertia': 2731229.4265126092}\n",
      "[2025-01-02 15:07:17,647] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 15:07:17,651] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 15:07:17,655] [INFO] [train_model]: log params: {'n_clusters': 3, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 15:07:17,662] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 15:07:17,865] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 15:07:17,866] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 15:07:18,048] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 15:07:18,053] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 15:07:18,053] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 15:07:18,184] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 15:07:18,185] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 15:07:18,465] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 15:07:18,465] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 15:07:18,763] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 5}\n",
      "[2025-01-02 15:07:19,244] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 15:07:19,499] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 15:07:19,504] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 15:07:19,510] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 15:07:19,513] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 15:07:22,670] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 15:07:22,671] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 15:50:56,414] [INFO] [evaluation]: Silhouette Score: 0.184\n",
      "[2025-01-02 15:50:56,416] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 15:50:56,417] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2168251.348\n",
      "[2025-01-02 15:50:56,418] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.18433768932848285), 'inertia': 2168251.34765663}\n",
      "[2025-01-02 15:50:56,418] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 15:50:56,424] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 15:50:56,427] [INFO] [train_model]: log params: {'n_clusters': 5, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 15:50:56,437] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "cluster_range = [3,5]\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    print(f\"Running pipeline with n_clusters={n_clusters}\")\n",
    "    \n",
    "    args_dict[\"override\"] = json.dumps({\n",
    "        \"mlflow.mlflow_experiment_name\": \"two_clusterings\",\n",
    "        \"model.kmeans.params.model_params.n_clusters\": n_clusters\n",
    "    })\n",
    "    \n",
    "    TM.run_training_pipeline(args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 13:20:24,640] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 13:20:24,642] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 13:20:24,823] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n",
      "2025/01/02 13:20:24 INFO mlflow.tracking.fluent: Experiment with name 'two_clusterings_2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 13:20:24,859] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 13:20:24,860] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 13:20:24,988] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 13:20:24,988] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 13:20:25,256] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 13:20:25,256] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 13:20:25,538] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 3}\n",
      "[2025-01-02 13:20:26,041] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 13:20:26,387] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 13:20:26,387] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 13:20:26,407] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 13:20:26,407] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 13:20:30,355] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 13:20:30,355] [INFO] [evaluation]: Compute silhouette score.\n",
      "[2025-01-02 14:04:01,874] [INFO] [evaluation]: Silhouette Score: 0.276\n",
      "[2025-01-02 14:04:01,874] [INFO] [evaluation]: Get inertia.\n",
      "[2025-01-02 14:04:01,874] [INFO] [evaluation]: Inertia (Sum of Squared Distances): 2731229.427\n",
      "[2025-01-02 14:04:01,874] [INFO] [train_model]: Evaluation metrics: {'silhouette_score': np.float64(0.2763466800819722), 'inertia': 2731229.4265126092}\n",
      "[2025-01-02 14:04:01,874] [INFO] [train_model]: log metric: silhouette_score\n",
      "[2025-01-02 14:04:01,890] [INFO] [train_model]: log metric: inertia\n",
      "[2025-01-02 14:04:01,897] [INFO] [train_model]: log params: {'n_clusters': 3, 'pca_n_components': 5, 'random_state': 42}\n",
      "[2025-01-02 14:04:01,901] [INFO] [train_model]: Training and evaluation completed. Artifacts and metrics logged to MLflow.\n",
      "[2025-01-02 14:04:02,180] [INFO] [utils]: Logger set up: ./logs.log\n",
      "[2025-01-02 14:04:02,180] [INFO] [utils]: Loading data from ./consumers_features.parquet.gzip\n",
      "[2025-01-02 14:04:02,375] [INFO] [utils]: Data loaded successfully with shape: (315462, 13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline with n_clusters=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-02 14:04:02,404] [INFO] [train_model]: Applying Standard Scaling to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items']\n",
      "[2025-01-02 14:04:02,405] [INFO] [transformations]: Standard scaling pipeline built successfully\n",
      "[2025-01-02 14:04:02,530] [INFO] [train_model]: Applying One-Hot Encoding to columns: {'favourite_metal': ['0', '1', '10', '13', '15', '16', '17', '22', '23', '24', '25', '3', '4', '5', '6', '7'], 'favourite_store_type': ['Concept Store', 'Online', 'Shop In Shop']}\n",
      "[2025-01-02 14:04:02,530] [INFO] [transformations]: Pipeline with one-hot encoding built successfully\n",
      "[2025-01-02 14:04:02,837] [INFO] [train_model]: Applying PCA to columns: ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with pca_n_components=5\n",
      "[2025-01-02 14:04:02,838] [INFO] [transformations]: PCA pipeline built successfully for columns ['recency', 'total_baskets', 'total_spend_money', 'total_refund_money', 'total_net_revenue', 'average_basket_spend', 'total_items_purchased', 'total_distinct_items_purchased', 'total_returned_items'] with 5 components\n",
      "[2025-01-02 14:04:03,117] [INFO] [train_model]: Initializing model: kmeans with parameters: {'n_clusters': 5}\n",
      "[2025-01-02 14:04:03,593] [INFO] [train_model]: Predicting transformed_data using the model.\n",
      "[2025-01-02 14:04:03,859] [INFO] [train_model]: log artifact: standard_scaling\n",
      "[2025-01-02 14:04:03,861] [INFO] [train_model]: log artifact: one_hot_encoding\n",
      "[2025-01-02 14:04:03,861] [INFO] [train_model]: log artifact: pca\n",
      "[2025-01-02 14:04:03,876] [INFO] [train_model]: log model: kmeans\n",
      "[2025-01-02 14:04:11,874] [INFO] [train_model]: Starting Evaluation.\n",
      "[2025-01-02 14:04:11,875] [INFO] [evaluation]: Compute silhouette score.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning pipeline with n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m args_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow.mlflow_experiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo_clusterings_2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.kmeans.params.model_params.n_clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_clusters\n\u001b[0;32m      9\u001b[0m })\n\u001b[1;32m---> 11\u001b[0m \u001b[43mTM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\train_model.py:199\u001b[0m, in \u001b[0;36mrun_training_pipeline\u001b[1;34m(args_dict)\u001b[0m\n\u001b[0;32m    191\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[0;32m    192\u001b[0m     sk_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    193\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m     signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[0;32m    195\u001b[0m     input_example\u001b[38;5;241m=\u001b[39minput_example\n\u001b[0;32m    196\u001b[0m )\n\u001b[0;32m    198\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Evaluation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m metrics \u001b[38;5;241m=\u001b[39m EV\u001b[38;5;241m.\u001b[39mevaluate_kmeans(model, transformed_data, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    200\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, metric_value \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\evaluation.py:31\u001b[0m, in \u001b[0;36mevaluate_kmeans\u001b[1;34m(model, transformed_data, model_config)\u001b[0m\n\u001b[0;32m     29\u001b[0m labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m     30\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompute silhouette score.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m silhouette_avg \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilhouette_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m silhouette_avg\n\u001b[0;32m     33\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilhouette Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msilhouette_avg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\\\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:139\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:303\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    299\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    300\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    301\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    302\u001b[0m )\n\u001b[1;32m--> 303\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    305\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2261\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2260\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m D_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 2261\u001b[0m     D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2262\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "File \u001b[1;32mc:\\Users\\a.iliopoulos_xe\\Desktop\\pandoras_ML\\assigment\\venv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:180\u001b[0m, in \u001b[0;36m_silhouette_reduce\u001b[1;34m(D_chunk, start, labels, label_freqs)\u001b[0m\n\u001b[0;32m    178\u001b[0m         sample_weights \u001b[38;5;241m=\u001b[39m D_chunk[i]\n\u001b[0;32m    179\u001b[0m         sample_labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m--> 180\u001b[0m         cluster_distances[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_freqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# intra_index selects intra-cluster distances within cluster_distances\u001b[39;00m\n\u001b[0;32m    185\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m n_chunk_samples\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluster_range = [3,5]\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    print(f\"Running pipeline with n_clusters={n_clusters}\")\n",
    "    \n",
    "    args_dict[\"override\"] = json.dumps({\n",
    "        \"mlflow.mlflow_experiment_name\": \"two_clusterings_2\",\n",
    "        \"model.kmeans.params.model_params.n_clusters\": n_clusters\n",
    "    })\n",
    "    \n",
    "    TM.run_training_pipeline(args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
